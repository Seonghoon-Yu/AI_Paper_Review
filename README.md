# Paper Reading
까먹으면 다시 보려고 정리합니다.

---

## Classification
- [Lenet-5(1998)](https://deep-learning-study.tistory.com/368), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/paper-implement-in-pytorch/blob/master/Classification/LeNet_5(1998).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/503)]

- [AlexNet(2012)](https://deep-learning-study.tistory.com/376), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/paper-implement-in-pytorch/blob/master/Classification/AlexNet(2012).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/518)]

- [Pseudo Label(2013)](https://deep-learning-study.tistory.com/553)

- PyTorch 구현 코드로 살펴보는 [Knowledge Distillation(2014)](https://deep-learning-study.tistory.com/699), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/Knowledge_distillation(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/700)], paper [[pdf](https://arxiv.org/abs/1503.02531)]

- [GoogLeNet(2014)](https://deep-learning-study.tistory.com/389), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/paper-implement-in-pytorch/blob/master/Classification/GoogLeNet(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/523)]

- [VGGNet(2014)](https://deep-learning-study.tistory.com/398), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/paper-implement-in-pytorch/blob/master/Classification/VGGnet(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/521)]

- [Inception-v3(2015)](https://deep-learning-study.tistory.com/517)

- [ResNet(2015)](https://deep-learning-study.tistory.com/473), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/paper-implement-in-pytorch/blob/master/Classification/ResNet(2015).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/534?category=983681)]

- [Pre-Activation ResNet(2016)](https://deep-learning-study.tistory.com/510), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/PreAct_ResNet(2016).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/540)]

- [WRN, Wide Residual Networks(2016)](https://deep-learning-study.tistory.com/519), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/Wide_ResNet(2016).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/542)]

- [SqueezeNet(2016)](https://deep-learning-study.tistory.com/520)

- [Inception-v4(2016)](https://deep-learning-study.tistory.com/525), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implement_in_PyTorch/blob/master/Classification/Inceptionv4(2016).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/537)]

- [PyramidNet(2017)](https://deep-learning-study.tistory.com/526)

- [DenseNet(2017)](https://deep-learning-study.tistory.com/528), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/DenseNet(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/545)]

- [Xception(2017)](https://deep-learning-study.tistory.com/529), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/Xception(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/548)]

- [MobileNetV1(2017)](https://deep-learning-study.tistory.com/532), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/Xception(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/549)]

- [ResNext(2017)](https://deep-learning-study.tistory.com/533), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/ResNext(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/558)]

- [PolyNet(2017)](https://deep-learning-study.tistory.com/535)

- [Residual Attention Network(2017)](https://deep-learning-study.tistory.com/536), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/Residual_Attention_Network(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/555)]

- [DPN(2017)](https://deep-learning-study.tistory.com/538)

- [Non-local Neural Network(2017)](https://deep-learning-study.tistory.com/749), paper [[pdf](https://arxiv.org/abs/1711.07971)]

- [SENet(2018)](https://deep-learning-study.tistory.com/539), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/SENet(2018).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/561)]

- [MobileNetV2(2018)](https://deep-learning-study.tistory.com/541)

- [ShuffleNet(2018)](https://deep-learning-study.tistory.com/544)

- [NasNet(2018)](https://deep-learning-study.tistory.com/543)

- [PNasNet(2018)](https://deep-learning-study.tistory.com/546)

- [ShuffleNet(2018)](https://deep-learning-study.tistory.com/547)

- [CondenseNet(2018)](https://deep-learning-study.tistory.com/550)

- [CBAM(2018)](https://deep-learning-study.tistory.com/666), paper [[pdf](https://arxiv.org/abs/1807.06521)]

- [Bag of Tricks(2019)](https://deep-learning-study.tistory.com/569)

- [MobileNetV3(2019)](https://deep-learning-study.tistory.com/551)

- [EfficientNet(2019)](https://deep-learning-study.tistory.com/552), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/EfficientNet(2019).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/563)]

- [SKNet(2019)](https://deep-learning-study.tistory.com/669), paper [[pdf](https://arxiv.org/abs/1903.06586)]

- [BiT(2019)](https://deep-learning-study.tistory.com/723). paper [[pdf](https://arxiv.org/abs/1912.11370)]

- [Noisy Student(2020)](https://deep-learning-study.tistory.com/554)

- [FixEfficientNet(2020)](https://deep-learning-study.tistory.com/557)

- [Meta Pseudo Labels(2020)](https://deep-learning-study.tistory.com/560)

- [Noise or Signal: The Role of Image Backgrounds in Object Recognition(2020)](https://deep-learning-study.tistory.com/693), paper [[pdf](https://arxiv.org/abs/2006.09994)]

- [VIT(2020)](https://deep-learning-study.tistory.com/716), paper [[pdf](https://arxiv.org/abs/2010.11929)], PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Classification/ViT(2020).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/807)]

- [Deit(2020)](https://deep-learning-study.tistory.com/806), paper [[pdf](https://arxiv.org/abs/2106.07023)]

- [EfficientNetV2(2021)](https://deep-learning-study.tistory.com/567)

- [Knowledge distillation: A good teacher is patient and consitent(2021)](https://deep-learning-study.tistory.com/701), paper [[pdf](https://arxiv.org/abs/2106.05237)]

- [MLP-Mixer(2021)](https://deep-learning-study.tistory.com/720), paper [[odf](https://arxiv.org/pdf/2105.01601.pdf)]

- [CvT(2021)](https://deep-learning-study.tistory.com/816), paper [[pdf](https://arxiv.org/abs/2103.15808)]

- [CeiT(2021)](https://deep-learning-study.tistory.com/811), paper [[pdf](https://arxiv.org/abs/2103.11816)]

- [Early Convolutions Help Transformers See Better(2021)](https://deep-learning-study.tistory.com/818), paper [[pdf](https://arxiv.org/abs/2106.14881)]

- [BoTNet(2021)](https://deep-learning-study.tistory.com/821), paper [[pdf](https://arxiv.org/abs/2101.11605)]

- [Conformer(2021)](https://deep-learning-study.tistory.com/852), paper [[pdf](https://arxiv.org/abs/2105.03889)]

- [Delving Deep into the Generalization of Vision Transformers under Distribution Shifts(2021)](https://deep-learning-study.tistory.com/824), paper [[pdf](https://arxiv.org/abs/2106.07617)]

- [Scaling Vision Transformers(2021)](https://deep-learning-study.tistory.com/828), paper [[pdf](https://arxiv.org/abs/2106.04560)]

- [CMT(2021)](https://deep-learning-study.tistory.com/829), paper [[pdf](https://arxiv.org/abs/2107.06263)]

## Object Detection

- [IoU(Intersection over Union)를 이해하고 파이토치로 구현하기](https://deep-learning-study.tistory.com/402)
- [비-최대 억제(NMS, Non-maximum Suppression)를 이해하고 파이토치로 구현하기](https://deep-learning-study.tistory.com/403)
- [mAP(mean Average Precision)을 이해하고 파이토치로 구현하기](https://deep-learning-study.tistory.com/407)

- [R-CNN(2013)](https://deep-learning-study.tistory.com/410)

- [SPPnet(2014)](https://deep-learning-study.tistory.com/445)

- [Fast R-CNN(2014)](https://deep-learning-study.tistory.com/456)

- [Faster R-CNN(2015)](https://deep-learning-study.tistory.com/464) 미완성 [PyTorch Code](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Object_Detection/Faster_R_CNN(2015)_%EB%AF%B8%EC%99%84%EC%84%B1.ipynb)

- [SSD(2016)](https://deep-learning-study.tistory.com/477)

- [YOLO v1(2016)](https://deep-learning-study.tistory.com/430)

- [R-FCN(2016)](https://deep-learning-study.tistory.com/570)

- [OHEM(2016)](https://deep-learning-study.tistory.com/501)

- [DSSD(2017)](https://deep-learning-study.tistory.com/566)

- [YOLO v2(2017)](https://deep-learning-study.tistory.com/433)

- [FPN(2017)](https://deep-learning-study.tistory.com/491)

- [RetinaNet(2017)](https://deep-learning-study.tistory.com/504) PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/RetinaNet(2017).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/616)]
- [RON(2017)](https://deep-learning-study.tistory.com/572)

- [DCN(2017)](https://deep-learning-study.tistory.com/575)

- [CoupleNet(2017)](https://deep-learning-study.tistory.com/602)

- [Soft-NMS(2017)](https://deep-learning-study.tistory.com/606)

- [RefineDet(2018)](https://deep-learning-study.tistory.com/609)

- [Cascade R-CNN(2018)](https://deep-learning-study.tistory.com/605)

- [YOLO v3(2018)](https://deep-learning-study.tistory.com/509), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Object_Detection/YOLOv3(2018).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/568)]

- [CornerNet(2018)](https://deep-learning-study.tistory.com/613)

- [M2Det(2019)](https://deep-learning-study.tistory.com/620)

- [CenterNet(2019)](https://deep-learning-study.tistory.com/622), paper [[pdf](https://arxiv.org/abs/1904.08189)]

- [Gaussian YOLOv3(2019)](https://deep-learning-study.tistory.com/624), paper [[pdf](https://arxiv.org/pdf/1904.04620)]

- [FCOS(2019)](https://deep-learning-study.tistory.com/625), paper [[pdf](https://arxiv.org/pdf/1904.01355.pdf)]

- [YOLOv4(2020)](https://deep-learning-study.tistory.com/626), paper [[pdf](https://arxiv.org/abs/2004.10934)]

- [EfficientDet(2020)](https://deep-learning-study.tistory.com/627), paper [[pdf](https://arxiv.org/abs/1911.09070)] 

- [CSPNet(2020)](https://deep-learning-study.tistory.com/632), paper [[pdf](https://arxiv.org/abs/1911.11929)]

- [DIoU Loss(2020)](https://deep-learning-study.tistory.com/634), paper [[pdf](https://arxiv.org/abs/1911.08287)], [Code](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Object_Detection/CIoU_Loss.py)

- [CircleNet(2020)](https://deep-learning-study.tistory.com/661), paper [[pdf](https://arxiv.org/pdf/2006.02474.pdf)]

- [DETR(2020)](https://deep-learning-study.tistory.com/748), paper [[pdf](https://arxiv.org/abs/2005.12872)]

- [ACT(2020)](https://deep-learning-study.tistory.com/789), paper [[pdf](https://arxiv.org/abs/2011.09315)]

- [Deformable DETR(2020)](https://deep-learning-study.tistory.com/825), paper [[pdf](https://arxiv.org/abs/2010.04159)]

- Localization Distillation for Dense Object Detection(2102)

- [CenterNet2(2021)](https://deep-learning-study.tistory.com/670), paper [[pdf](https://arxiv.org/abs/2103.07461)]

- [Swin Transformer(2021)](https://deep-learning-study.tistory.com/728), paper [[pdf](https://arxiv.org/pdf/2103.14030v1.pdf)]

- [YOLOr(2021)](https://deep-learning-study.tistory.com/739), paper [[pdf](https://arxiv.org/pdf/2105.04206v1.pdf)]

- [YOLOS(2021)](https://deep-learning-study.tistory.com/826), paper [[pdf](https://arxiv.org/abs/2106.00666)]

- Dynamic Head, Unifying Object Detection Heads with Attention(2021), paper [[pdf](https://arxiv.org/abs/2106.08322)]

- [Pix2Seq(2021)](https://deep-learning-study.tistory.com/866), paper [[pdf](https://arxiv.org/abs/2109.10852)]

- Anchor DETR, Query Design for Transformer-Based Object Detection(2021), paper [[pdf](https://arxiv.org/abs/2109.07107)]

- DAB-DETR, Dynamic Anchor Boxes are Better Queries for DETR(2022), paper [[pdf](https://arxiv.org/abs/2201.12329)]

- DN-DETR, Accelerate DETR Training by Introducing Query DeNoising(2022), paper [[pdf](https://arxiv.org/abs/2203.01305)]

- DINO, DETR with Imporved DeNoising Anchor Boxes for End-to-End Object Detection(2022), paper [[pdf](https://arxiv.org/abs/2203.03605)]



## Segmentation

- [DeepLabV1(2014)](https://deep-learning-study.tistory.com/564)

- [FCN(2015)](https://deep-learning-study.tistory.com/562)

- [DeConvNet(2015)](https://deep-learning-study.tistory.com/565)

- [DilatedNet(2015)](https://deep-learning-study.tistory.com/664), paper [[pdf](https://arxiv.org/abs/1511.07122)]

- PyTorch 구현 코드로 살펴보는 [SegNet(2015)](https://deep-learning-study.tistory.com/672), paper [[pdf](https://arxiv.org/pdf/1511.00561.pdf)]

- [PSPNet(2016)](https://deep-learning-study.tistory.com/864), paper [[pdf](https://arxiv.org/abs/1612.01105)]

- [DeepLabv3(2017)](https://deep-learning-study.tistory.com/877), paper [[pdf](https://arxiv.org/abs/1706.05587)]

- [Mask R-CNN(2017)](https://deep-learning-study.tistory.com/571)

- [PANet(2018)](https://deep-learning-study.tistory.com/637), paper [[pdf](https://arxiv.org/abs/1803.01534)]

- [Panoptic Segmentation(2018)](https://deep-learning-study.tistory.com/861), paper [[pdf](https://arxiv.org/abs/1801.00868)]

- Weakly- and Semi-Supervised Panoptic Segmentation(2018), paper [[pdf](https://arxiv.org/abs/1808.03575)]

- [Panoptic Segmentation with a Joint Semantic and Instance Segmentation Network(2018)](https://deep-learning-study.tistory.com/862), paper [[pdf](https://arxiv.org/abs/1809.02110)]

- [Single Network Panoptic Segmentation for Street Scene Understanding(2019)](https://deep-learning-study.tistory.com/863), paper [[pdf](https://arxiv.org/abs/1902.02678)]

- [Panoptic Feature Pyramid Networks(2019)](https://deep-learning-study.tistory.com/867), paper [[pdf](https://arxiv.org/abs/1901.02446)]

- [IMP: Instance Mask Projection for High Accuracy Semantic Segmentation of Things(2019)](https://deep-learning-study.tistory.com/865), paper [[pdf](https://arxiv.org/abs/1906.06597)]

- [Object-Contextual Representations for Semantic Segmentation(2019)](https://deep-learning-study.tistory.com/894), paper [[pdf](https://arxiv.org/abs/1909.11065)]

- [CondInst, Conditional Convolution for Instance Segmentation(2020)](https://deep-learning-study.tistory.com/961), paper [[pdf](https://arxiv.org/abs/2003.05664)]

- Max-DeepLab, End-to-End Panoptic Segmentation wtih Mask Transformers, paper [[pdf](https://arxiv.org/abs/2012.00759)]

- [MaskFormer, Per-Pixel Classification is Not All You Need for Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/940), paper [[pdf](https://arxiv.org/abs/2107.06278)]

- [Open-World Entity Segmentation(2021)](https://deep-learning-study.tistory.com/962), paper [[pdf](https://arxiv.org/abs/2107.14228)]

- Prompt based Multi-modal Image Segmentation(2021), paper [[pdf](https://arxiv.org/abs/2112.10003)]

- DenseCLIP, Language-Guided Dense Prediction with Context-Aware Prompting, paper [[pdf](https://arxiv.org/abs/2112.10003)]

- [Mask2Former, Masked-attention Mask Transformer for Universal Image Segmentation(2021)](https://arxiv.org/abs/2112.01527)

- [SeMask<, Semantically Masked Transformers for Semantic Segmentation(2021)](https://arxiv.org/abs/2112.12782)



## Self-supervised Learning
- [Constrative Loss(2006)](https://deep-learning-study.tistory.com/724), paper [[pdf](http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf)]

- [Exemplar-CNN(2014)](https://deep-learning-study.tistory.com/715), paper [[pdf](https://arxiv.org/abs/1406.6909)]

- [Unsupervised Learning of Visual Representation using Videos](https://deep-learning-study.tistory.com/773), paper [[pdf](https://arxiv.org/abs/1505.00687)]

- [Context Prediction(2015)](https://deep-learning-study.tistory.com/717), paper [[pdf](https://arxiv.org/abs/1505.05192)]

- [Jigsaw Puzzles(2016)](https://deep-learning-study.tistory.com/719), paper [[odf](https://arxiv.org/pdf/1603.09246.pdf)]

- [Colorful Image Coloriztion(2016)](https://deep-learning-study.tistory.com/722), paper [[pdf](https://arxiv.org/abs/1603.08511)]

- [Deep InfoMax(2018)](https://deep-learning-study.tistory.com/768), paper [[pdf](https://arxiv.org/abs/1808.06670)]

- [Deep Cluster(2018)](https://deep-learning-study.tistory.com/766), paper [[pdf](https://arxiv.org/abs/1807.05520)]

- [IIC(2018)](https://deep-learning-study.tistory.com/784), paper [[pdf](https://arxiv.org/abs/1807.06653)]

- [Rotation(2018)](https://deep-learning-study.tistory.com/804), paper [[pdf](https://arxiv.org/abs/1803.07728)]

- [Unsupervised Feature Learning via Non-Parametric Instance Discrimination(2018)](https://deep-learning-study.tistory.com/769), paper [[pdf](https://arxiv.org/abs/1805.01978)]

- [ADMIN(2019)](https://deep-learning-study.tistory.com/817), paper [[pdf](https://arxiv.org/abs/1906.00910)]

- [Contrastive Multiview Coding(2019)](https://deep-learning-study.tistory.com/814), paper [[pdf](https://deep-learning-study.tistory.com/814)]

- [MoCo(2019)](https://deep-learning-study.tistory.com/730), paper [[pdf](https://arxiv.org/abs/1911.05722)]

- [SeLa(2019)](https://deep-learning-study.tistory.com/760), paper [[pdf](https://arxiv.org/abs/1911.05371)]

- [SimCLR(2020)](https://deep-learning-study.tistory.com/731), paper [[pdf](https://arxiv.org/abs/2002.05709)]

- [MoCov2(2020)](https://deep-learning-study.tistory.com/743), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/MoCov2_Pytorch_tutorial/blob/main/MoCov2.ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/744)], paper [[pdf](https://arxiv.org/pdf/2003.04297.pdf)]

- [SimSiam(2020)](https://deep-learning-study.tistory.com/745), paper [[pdf](https://arxiv.org/pdf/2011.10566.pdf)]

- [Understanding the Behaviour of Contrastive Loss(2020)](https://deep-learning-study.tistory.com/753), paper [[pdf](https://arxiv.org/pdf/2012.09740.pdf)]

- [BYOL(2020)](https://deep-learning-study.tistory.com/753), paper [[pdf](https://arxiv.org/abs/2012.09740)]

- [SwAV(2020)](https://deep-learning-study.tistory.com/761), paper [[pdf](https://arxiv.org/abs/2006.09882)]

- [PCL(2020)](https://deep-learning-study.tistory.com/822), paper [[pdf](https://arxiv.org/abs/2005.04966)]

- [SimCLRv2(2020)](https://deep-learning-study.tistory.com/778), paper [[pdf](https://arxiv.org/abs/2006.10029)]

- [Supervised Contrastive Learning(2020)](https://deep-learning-study.tistory.com/819), paper [[pdf](https://arxiv.org/abs/2004.11362)]

- [DenseCL(2020), Dense Contrastive Learning for Self-Supervised Visual Pre-Training](https://deep-learning-study.tistory.com/935), paper [[pdf](https://arxiv.org/abs/2011.09157)]

- [DetCo(2021)](https://deep-learning-study.tistory.com/843), paper [[pdf](https://arxiv.org/abs/2102.04803)

- [SCRL(2021)](https://deep-learning-study.tistory.com/831), paper [[pdf](https://arxiv.org/abs/2103.06122)]

- [MoCov3(2021)](https://deep-learning-study.tistory.com/746), paper [[pdf](https://arxiv.org/abs/2104.02057)]

- [DINO(2021)](https://deep-learning-study.tistory.com/827), paper [[pdf](https://arxiv.org/abs/2104.14294)]

- [EsViT(2021)](https://deep-learning-study.tistory.com/845), paper [[pdf](https://arxiv.org/abs/2106.09785)]

- [Masked Autoencoders Are Scalable Vision Learners(2021)](https://deep-learning-study.tistory.com/907), paper [[pdf](https://arxiv.org/abs/2111.06377)]



## Video SSL

- [Tracking Emerges by Colorizing Videos(2018)](https://deep-learning-study.tistory.com/830), paper [[pdf](https://arxiv.org/pdf/1806.09594.pdf)]

- [Self-supervised Learning for Video Correspondence Flow(2019)](https://deep-learning-study.tistory.com/832), paper [[pdf](https://arxiv.org/abs/1905.00875)]


- [Learning Correspondence from the Cycle-consistency of Time(2019)](https://deep-learning-study.tistory.com/833), paper [[pdf](https://arxiv.org/abs/1903.07593)]

- [Joint-task Self-supervised Learning for Temporal Correspondence(2019)](https://deep-learning-study.tistory.com/835), paper [[pdf](https://arxiv.org/abs/1909.11895)]

- [MAST(2020)](https://deep-learning-study.tistory.com/836), https://arxiv.org/abs/2002.07793

- [Space-Time Correspondence as a Contrastive Random Walk(2020)](https://deep-learning-study.tistory.com/839), paper [[pdf](https://arxiv.org/abs/2006.14613)]

- [Contrastive Transformation for Self-supervised Correspondence Learning(2020)](https://deep-learning-study.tistory.com/837), paper [[pdf](https://arxiv.org/abs/2012.05057)]

- [Mining Better Samples for Contrastive Learning of Temporal Correspondence(2021)](https://deep-learning-study.tistory.com/840), paper [[pdf](https://openaccess.thecvf.com/content/CVPR2021/html/Jeon_Mining_Better_Samples_for_Contrastive_Learning_of_Temporal_Correspondence_CVPR_2021_paper.html)]

- [VFS(2021)](https://deep-learning-study.tistory.com/841), paper [[pdf](https://arxiv.org/abs/2103.17263)]

- [Contrastive Learning of Image Representations with Cross-Video Cycle-Consistency](https://deep-learning-study.tistory.com/842), paper [[pdf](https://arxiv.org/abs/2105.06463)]

- [ViCC(2021)](https://deep-learning-study.tistory.com/847), paper [[pdf](https://arxiv.org/abs/2106.10137)]


## Semi-supervised Learning

- [Temporal ensembling for semi-supervised learning(2016)](https://deep-learning-study.tistory.com/757) , paper [[pdf](https://arxiv.org/abs/1610.02242)]

- [Mean teachers are better role models(2017)](https://deep-learning-study.tistory.com/758), paper [[pdf](https://arxiv.org/abs/1703.01780)]

- [Consistency-based Semi-supervised Learning for Object Detection(2019)](https://deep-learning-study.tistory.com/735), paper [[pdf](https://papers.nips.cc/paper/2019/hash/d0f4dae80c3d0277922f8371d5827292-Abstract.html)]

- [PseudoSeg, Designing Pseudo Labels for Semantic Segmentation(2020)](https://deep-learning-study.tistory.com/953), paper [[pdf](https://arxiv.org/abs/2010.09713)]

- [ReCo, Bootstrapping Semantic Segmentation with Regional Contrast(2021)](https://deep-learning-study.tistory.com/868), paper [[pdf](https://arxiv.org/abs/2104.04465)]

- [Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision(2021)](https://deep-learning-study.tistory.com/948), paper [[pdf](https://arxiv.org/abs/2106.01226)]

- [Soft Teacher(2021), End-to-End Semi-Supervised Object Detection with Soft Teacher](https://deep-learning-study.tistory.com/949), paper [[pdf](https://arxiv.org/abs/2106.09018)]

- [CaSP(2021), Class-agnostic Semi-Supervised Pretraining for Detection & Segmentation](https://deep-learning-study.tistory.com/960), paper [[pdf](https://arxiv.org/abs/2112.04966)]


## weakly
- [Class Activation Map(CAM), Learning Deep Features for Discriminative Localization](https://deep-learning-study.tistory.com/954), paper [[pdf](https://arxiv.org/abs/1512.04150)]

- [Grad-CAM, Visual Explanations from Deep Networks via Gradient based Localization](https://deep-learning-study.tistory.com/955), paper [[pdf](https://arxiv.org/abs/1610.02391)]

- [Zoom-CAM, Generating Fine-grained Pixel Annotations from Image Labels(2020)](https://deep-learning-study.tistory.com/956), paper [[pdf](https://arxiv.org/abs/2010.08644)]

- [GETAM: Gradient-weighted Element-wise Transformer Attention Map for Weakly-supervised Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/958), paper [[pdf](https://arxiv.org/abs/2112.02841)]



## Video Recognition
- [Learning Spatiotemporal Features with 3D Convolutional Network(2014)](https://deep-learning-study.tistory.com/751), paper [[pdf](https://arxiv.org/abs/1412.0767)]

- [Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset(2017)](https://deep-learning-study.tistory.com/756), paper [[pdf](https://arxiv.org/abs/1705.07750)]

- [SlowFast Networks for Video Recognition(2018)](https://deep-learning-study.tistory.com/765), paper [[pdf](https://arxiv.org/abs/1812.03982)]

- [TSM(2018)](https://deep-learning-study.tistory.com/772), paper [[pdf](https://arxiv.org/abs/1811.08383)]

- [GCNet(2019)](https://deep-learning-study.tistory.com/780), paper [[pdf](https://arxiv.org/abs/1904.11492)]

- [Drop an Octave(2019)](https://deep-learning-study.tistory.com/788), paper [[pdf](https://arxiv.org/abs/1904.05049)]

- [STM(2019)](https://deep-learning-study.tistory.com/800), paper [[pdf](https://arxiv.org/abs/1908.02486)]

- [X3D(2020)](https://deep-learning-study.tistory.com/855), paper [[pdf](https://arxiv.org/abs/2004.04730)]


- [VTN(2021)](https://deep-learning-study.tistory.com/850). paper [[pdf](https://arxiv.org/abs/2102.00719)]

- [TimeSformer(2021)](https://deep-learning-study.tistory.com/848), paper [[pdf](https://arxiv.org/abs/2102.05095)], Youtube [[link](https://youtu.be/xSf40PZjTxQ)]

- [ViViT(2021)](https://deep-learning-study.tistory.com/838), paper [[pdf](https://arxiv.org/abs/2103.15691)]

- [MViT(2021)](https://deep-learning-study.tistory.com/849), paper [[pdf](https://arxiv.org/abs/2104.11227)] 

- [X-ViT(2021)](https://deep-learning-study.tistory.com/856), paper [[pdf](https://arxiv.org/abs/2106.05968)]

- [Video Swin Transformer(2021)](https://deep-learning-study.tistory.com/846), paper [[pdf](https://arxiv.org/abs/2106.13230)]

- [Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition(2021)](https://deep-learning-study.tistory.com/859), paper [[pdf](https://arxiv.org/abs/2106.05058)]

- [VLF(2021)](https://deep-learning-study.tistory.com/857), paper [[pdf](https://arxiv.org/abs/2107.00451)], Youtube [[link](https://youtu.be/OtVHC1s3yzg)]



## Video Segmentation

- [VisTR(2020)](https://deep-learning-study.tistory.com/834), paper [[pdf](https://arxiv.org/abs/2011.14503)]

## Zero Shot Classification
- [DeViSE, A Deep Visual-Semantic Embedding Model(2013)](https://deep-learning-study.tistory.com/909), paper [[pdf](https://papers.nips.cc/paper/2013/hash/7cce53cf90577442771720a370c3c723-Abstract.html)]

- [Zero-shot Learning via Shared-Reconstruction-Graph Pursuit(2017)](https://deep-learning-study.tistory.com/910), paper [[pdf](https://arxiv.org/abs/1711.07302)]

- [A Generative Adversarial Approach for Zero-Shot Learning from Noisy Texts(2017)](https://deep-learning-study.tistory.com/903), paper [[pdf](https://arxiv.org/abs/1712.01381)]

- [f-VAEGAN-D2, A Feature Generating Framework for Any Shot Learning(2019)](https://deep-learning-study.tistory.com/944), paper [[pdf](https://arxiv.org/abs/1903.10132)]

- [TCN(2019), Transferable Contrastive Network for Generalized Zero-Shot Learning](https://deep-learning-study.tistory.com/927), paper [[pdf](https://arxiv.org/abs/1908.05832)]

- [Rethinking Zero-Shot Learning: A Conditional Visual Classification Perspective(2019)](https://deep-learning-study.tistory.com/928), paper [[pdf](https://arxiv.org/abs/1909.05995)]

- [Convolutional Prototype Learning for Zero-Shot Recognition(2019)](https://deep-learning-study.tistory.com/931), paper [[pdf](https://arxiv.org/abs/1910.09728)]


- [DRN, Class-Prototype Discriminative Network for Generalized Zero-Shot Learning(2020)](https://deep-learning-study.tistory.com/930), paper [[pdf](https://ieeexplore.ieee.org/abstract/document/8966463)]

- [DAZLE(2020), Fine-Grained Generalized Zero-Shot Learning via Dense Attribute-Based Attention](https://deep-learning-study.tistory.com/915), paper [[pdf](https://openaccess.thecvf.com/content_CVPR_2020/papers/Huynh_Fine-Grained_Generalized_Zero-Shot_Learning_via_Dense_Attribute-Based_Attention_CVPR_2020_paper.pdf)]

- [IPN(2021), Isometric Propagation Network for Generalized Zero-Shot Learning](https://deep-learning-study.tistory.com/932), paper [[pdf](https://arxiv.org/abs/2102.02038)]


- [CE-GZSL(2021), Contrastive Embedding for Generalized Zero-Shot Learning](https://deep-learning-study.tistory.com/926), paper [[pdf](https://arxiv.org/abs/2103.16173)]

- [Task-Independent Knowledge Makes for Transferable Represenatations for Generalized Zero-Shot Learning(2021)](https://deep-learning-study.tistory.com/934), paper [[pdf](https://arxiv.org/abs/2104.01832)]

- [Zero-Shot Learning via Contrastive Learning on Dual Knowledge Graphs(2021)](https://deep-learning-study.tistory.com/933), paper [[pdf](https://ieeexplore.ieee.org/document/9607851)]

- [FREE: Feature Refinement for Generalized Zero-Shot Learning(2021)](https://deep-learning-study.tistory.com/936), paper [[pdf](https://arxiv.org/abs/2107.13807)]

- [ALIGN(2021), Scaling Up Visual and Vision-Language Representation Learning with Noisy Text Supervision](https://deep-learning-study.tistory.com/916), paper [[pdf](https://arxiv.org/abs/2102.05918)]

- [LiT: Zero-Shot Transfer with Locked-image Text Tuning(2021)](https://deep-learning-study.tistory.com/911), paper [[pdf](https://arxiv.org/abs/2111.07991)]

- [Generalized Category Discovery(2022)](https://deep-learning-study.tistory.com/945), paper [[pdf](https://arxiv.org/abs/2201.02609)]

## Zero Shot Detection

- Synthesizing the Unseen for Zero-shot Object Detection(2020), paper [[pdf](https://arxiv.org/abs/2010.09425)] 

- [ViLD(2021), Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation](https://deep-learning-study.tistory.com/947), paper [[pdf](https://arxiv.org/abs/2104.13921)]

- Robust Region Feature Synthesizer for Zero-Shot Object Detection(2022), paper [[pdf](https://arxiv.org/abs/2201.00103)]

- [Detic(2022), Detecting Twenty-thousand Classes using Image-level Supervision](https://deep-learning-study.tistory.com/957), paper [[pdf](https://arxiv.org/abs/2201.02605)]


## Zero Shot Segmentation

- [Zero-Shot Semantic Segmentation(2019)](https://deep-learning-study.tistory.com/872), paper [[pdf](https://arxiv.org/abs/1906.00817)]

- [Semantic Projection Network for Zero- and Few-Label Semantic Segmentation(2020)](https://deep-learning-study.tistory.com/876), paper [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xian_Semantic_Projection_Network_for_Zero-_and_Few-Label_Semantic_Segmentation_CVPR_2019_paper.pdf)]

- [Learning unbiased zero-shot semantic segmentation networks via transductive transfer(2020)](https://deep-learning-study.tistory.com/891), paper [[pdf](https://arxiv.org/abs/2007.00515)]

- [A review of Generalized Zero-Shot Learning Methods(2020)](https://deep-learning-study.tistory.com/873), paper [[pdf](https://arxiv.org/abs/2011.08641)]

- [Consistent Structural Relation Learning for Zero-Shot Segmentation(2020](https://deep-learning-study.tistory.com/885), paper [[pdf](https://proceedings.neurips.cc/paper/2020/hash/7504adad8bb96320eb3afdd4df6e1f60-Abstract.html)]

- [Uncertainty-Aware Learning for Zero-Shot Semantic Segmentation(2020)](https://deep-learning-study.tistory.com/884), paper [[pdf](https://proceedings.neurips.cc/paper/2020/hash/f73b76ce8949fe29bf2a537cfa420e8f-Abstract.html)]

- [Context-aware Feature Generation for Zero-shot Semantic Segmentation(2020)](https://deep-learning-study.tistory.com/874), paper [[pdf](https://arxiv.org/abs/2008.06893)]

- [Recursive Training for Zero-Shot Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/889), paper [[pdf](https://arxiv.org/abs/2103.00086)]

- [Zero-Shot Instance Segmentation(2021)](https://deep-learning-study.tistory.com/892), paper [[pdf](https://arxiv.org/abs/2104.06601)]

- [A Closer Look at Self-training for Zero-Label Segmantic Segmentation(2021)](https://deep-learning-study.tistory.com/883), paper [[pdf](https://arxiv.org/abs/2104.11692)]

- [Prototypical Matching and Open Seg Rejection for Zero-Shot Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/929), paper [[pdf](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Prototypical_Matching_and_Open_Set_Rejection_for_Zero-Shot_Semantic_Segmentation_ICCV_2021_paper)]

- [SIGN(2021), Spatial-information Incorporated Generative Network for GGeneralized Zero-shot Semantic Segmentation](https://deep-learning-study.tistory.com/875), paper [[pdf](https://arxiv.org/abs/2108.12517)]

- [Exploiting a Joint Embedding Space for Generalized Zero-Shot Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/879), paper [[pdf](https://arxiv.org/abs/2108.06536)]

- [Languager Driven Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/890), paper [[pdf](https://openreview.net/forum?id=RriDjddCLN)]

- Zero-Shot Semantic Segmentation via Spatial and Multi-Scale Aware Visual Class Embedding, paper [[pdf](https://www.semanticscholar.org/paper/Zero-Shot-Semantic-Segmentation-via-Spatial-and-Cha-Wang/9d3d4d413125bb27681117b947320717d8deadfe)]

- [DenseCLIP: Extract Free Dence Labels from CLIP(2021)](https://deep-learning-study.tistory.com/946), paper [[pdf](https://arxiv.org/abs/2112.01071)]

- [Decoupling Zero-Shot Semantic Segmentation(2021)](https://deep-learning-study.tistory.com/943), paper [[pdf](https://arxiv.org/abs/2112.07910)]

- [A Simple Baseline for Zero-Shot Semantic Segmentation with Pre-trained Vision-language Model(2021)](https://deep-learning-study.tistory.com/939), paper [[pdf](https://arxiv.org/pdf/2112.14757.pdf)]

- [Open-Vocabulary Image Segmentation(2021)](https://deep-learning-study.tistory.com/942), paper [[pdf](https://arxiv.org/abs/2112.12143)]


## Few-Shot, Meta Learning
- [Matching Networks for One Shot Learning(2016)](https://deep-learning-study.tistory.com/941), paper [[pdf](https://arxiv.org/abs/1606.04080)]

- [Learning to Compare: Relation Network for Few-Shot Learning(2017)](https://deep-learning-study.tistory.com/937), paper [[pdf](https://arxiv.org/abs/1711.06025)]


## Prompting and Vision-Language Model

cv

- [CPT, Colorful Prompt Tuning for Pre-trained Vision-Language Models](https://arxiv.org/abs/2109.11797)

- [CoOp(2021), Learning to Prompt for Vision-Language Models](https://arxiv.org/abs/2109.01134)

- [CLIP-Adapter, Better Vision-Language Models with Feature Adapters(2021)](https://arxiv.org/abs/2110.04544)

- [Tip-Adapter, Training-free CLIP-Adapter for Better Vision-Language Modeling](https://arxiv.org/abs/2111.03930)

- [Prompt-Based Multi-Model Image Segmentation(2021)](https://arxiv.org/abs/2112.10003)

- [DenseCLIP, Language-Guided Dense Prediction with Context-Aware Prompting(2021)](https://arxiv.org/abs/2112.01518)

- Prompting Visual-Language Models for Efficient Video Understanding, paper [[pdf](https://arxiv.org/abs/2112.04478)]

- Conditianl Prompt Learning for Visiona-Language Models, paper [[pdf](https://arxiv.org/abs/2203.05557)]

nlp

- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing(2021)](https://arxiv.org/abs/2107.13586)




## Image Processing
- PyTorch 구현 코드로 살펴보는 [SRCNNe(2014)](https://deep-learning-study.tistory.com/687), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/Super_Resolution/SRCNN(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/688)], paper [[pdf](https://arxiv.org/abs/1501.00092)]

- [FlowNet(2015)](https://deep-learning-study.tistory.com/870), paper [[pdf](https://arxiv.org/abs/1504.06852)]

- [PWC-Net(2017)](https://deep-learning-study.tistory.com/871), paper [[pdf](https://arxiv.org/abs/1709.02371)]

- [Residual Non-local Attention Networks for Image Restoration(2019)](https://deep-learning-study.tistory.com/853), paper [[pdf](https://arxiv.org/abs/1903.10082)]



## 3D Vision

- [Convolutional-Recursive Deep Learning for 3D Object Classification(2012)](https://deep-learning-study.tistory.com/694), paper [[pdf](https://papers.nips.cc/paper/2012/file/3eae62bba9ddf64f69d49dc48e2dd214-Paper.pdf)]

- [PointNet(2016)](https://deep-learning-study.tistory.com/702), paper [[pdf](https://arxiv.org/abs/1612.00593)]

- [Set Transformer(2018)](https://deep-learning-study.tistory.com/777), paper [[pdf](https://arxiv.org/abs/1810.00825)]

- [Centroid Transformer(2021)](https://deep-learning-study.tistory.com/795), paper [[pdf](https://arxiv.org/abs/2102.08606)]



## NLP
- PyTorch 코드로 살펴보는 [Seq2Seq(2014)](https://deep-learning-study.tistory.com/685), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/NLP/Seq2Seq(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/686)], paper [[pdf](https://arxiv.org/abs/1409.3215)]

- PyTorch 코드로 살펴보는 [GRU(2014)](https://deep-learning-study.tistory.com/691), paper [[pdf](https://arxiv.org/abs/1406.1078)]

- PyTorch 코드로 살펴보는 [Attention(2015)](https://deep-learning-study.tistory.com/697), paper [[odf](https://arxiv.org/pdf/1409.0473.pdf)]

- PyTorch 코드로 살펴보는 [Convolutional Sequence to Sequence Learning(2017)](https://deep-learning-study.tistory.com/704), paper [[pdf](https://arxiv.org/pdf/1705.03122.pdf)]

- PyTorch 코드로 살펴보는 [Transforemr(2017)](https://deep-learning-study.tistory.com/710), paper [[pdf](https://arxiv.org/abs/1706.03762)]

- [BERT(2018)](https://deep-learning-study.tistory.com/770), paper [[pdf](https://arxiv.org/abs/1810.04805)]

- [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators(2020)](https://deep-learning-study.tistory.com/921), paper [[pdf](https://arxiv.org/abs/2003.10555)]

### GAN
- PyTorch 구현 코드로 살펴보는 [GAN(2014)](https://deep-learning-study.tistory.com/638), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/GAN/GAN(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/639)], paper [[pdf](https://arxiv.org/pdf/1406.2661.pdf)]

- PyTorch 구현 코드로 살펴보는 [CGAN(2014)](https://deep-learning-study.tistory.com/640), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/GAN/CGAN(2014).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/641)], paper [[pdf](https://arxiv.org/abs/1411.1784)]

- [Generative Moment Matching Network(2015)](https://deep-learning-study.tistory.com/893), paper [[pdf](https://arxiv.org/abs/1502.02761)]

- PyTorch 구현 코드로 살펴보는 [DCGAN(2015)](https://deep-learning-study.tistory.com/642), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/GAN/pix2pix(2016).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/646)], paper [[pdf](https://arxiv.org/abs/1511.06434)]

- PyTorch 구현 코드로 살펴보는 [Pix2Pix(2016)](https://deep-learning-study.tistory.com/645), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/GAN/DCGAN(2015).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/643)], paper [[pdf](https://arxiv.org/abs/1611.07004)]


## Active Learning
- [Towards Reducing Labeling Cost in Deep Object Detection(2021)](https://deep-learning-study.tistory.com/732), paper [[pdf](https://arxiv.org/abs/2106.11921)]

## Pose estimation
- [Hourglass(2016)](https://deep-learning-study.tistory.com/617)

## long tail
- [Class-Balanced Loss(2019)](https://deep-learning-study.tistory.com/671), paper [[pdf](https://arxiv.org/pdf/1901.05555.pdf)]

- [Seesaw Loss for Long-Tailed Instance Segmentation(2020)](https://deep-learning-study.tistory.com/902), paper [[pdf](https://arxiv.org/abs/2008.10032)]


## Face Recognition
- Pytorch 구현 코드로 살펴보는 [FaceNet(2015)](https://deep-learning-study.tistory.com/681), paper [[pdf](https://arxiv.org/pdf/1503.03832.pdf)]

## Model Compression
- [Deep Compression(2016)](https://deep-learning-study.tistory.com/683), paper [[pdf](https://arxiv.org/abs/1510.00149)]

## Activation Function
- [Mish(2019)](https://deep-learning-study.tistory.com/636), paper [[pdf](https://arxiv.org/abs/1908.08681)]

## Augmentation
- [CutMix(2019)](https://deep-learning-study.tistory.com/633), paper [[pdf](https://arxiv.org/abs/1905.04899)]

- [Learning Data Augmentation Strategies for Object Detection(2019](https://deep-learning-study.tistory.com/705), paper [[pdf](https://arxiv.org/pdf/1906.11172.pdf)]

- [Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation(2020)](https://deep-learning-study.tistory.com/708), paper [[pdf](https://arxiv.org/abs/2012.07177)]

## Style Transfer
- PyTorch 구현 코드로 살펴보는 [A Neural Algorithm of Artistic Style(2016)](https://deep-learning-study.tistory.com/679), PyTorch Code [[Google Colab](https://github.com/Seonghoon-Yu/Paper_Review_and_Implementation_in_PyTorch/blob/master/style_transfer/style_transfer(2015).ipynb) / [Blog Posting](https://deep-learning-study.tistory.com/680)], paper [[pdf](https://arxiv.org/abs/1508.06576)]

## Regularization
- [DropBlock(2018)](https://deep-learning-study.tistory.com/631), paper [[pdf](https://arxiv.org/abs/1810.12890)]

## Normalization

- [Batch Normalization(2015)](https://deep-learning-study.tistory.com/421)

- [Group Normalization(2018)](https://deep-learning-study.tistory.com/726), paper [[pdf](https://arxiv.org/abs/1803.08494)]

- [Cross iteration BN(2020)](https://deep-learning-study.tistory.com/635), paper [[pdf](https://arxiv.org/abs/2002.05712)]

## Optimization

- [An overview of gradient descent optimization algorithm(2017)](https://deep-learning-study.tistory.com/415)

- [AdamW(2017)](https://deep-learning-study.tistory.com/750), paper [[pdf](https://arxiv.org/abs/1711.05101)]

